%%HYPERFIT
% Version 1.0 2020-06-16
% Author: Joe Shirley
% <a href="matlab: web('https://www.mathworks.com')">Dog</a>
% <b href="">Dog</b>
% 
% Required Parameters:
%   data         - These are  the X and Y values to fit. This should be a
%                  matrix which consistst of two column vectors.
%
%   func         - This is the function you are fitting to. This is a
%                  character vector. 'a*exp(-x/b) + c' is an example.
%
%   fitOpts      - These are fit options such as the fit algorithm and
%                  tolerance. They should be generated with 'fitoptions.'
%                  Startpoints will be determined from the upper and lower
%                  bounds, so don't set the 'Startpoint' parameter.
% 
% Optional Parameters:
%   numAvg       - This is should be an integer which is the number of
%                  times (loop iterations) you want to fit the data. By
%                  default this value is 100.
%
%   startPoint   - This specifies the algorithm for finding the start point
%                  for each iteration of the loop. By default it is a
%                  random number between the upper and lower bounds.
%                  Options include: 'rand' 'mean' 'low'... (see code)
% 
% Examples:
%   result = hyperfit(data, 'ax + b', fitOpts)
%       The data is fit to the linear equation 'ax + b' 100 times with
%       randomized starting values. A structure is returned that contains:
%       all fitting parameters, the average fit, a final fit starting at
%       the average, the goodness of the final fit, the coefficients
%       associated with the final fit, and the 95 % confidence interval on
%       those coefficients.
%
%   result = hyperfit(data, 'ax + b', fitOpts, 'numAvg', 10)
%       Same as the first, but we only average 10 fits now.
%
%   result = hyperfit(data, 'ax + b', fitOpts, 'startPoint', 'mean')
%       Same as the first, but instead of starting at a random point for
%       each fit, we start at the mean. This is useless.
%
%   result = hyperfit(data, 'ax + b', fitOpts, 'numAvg', 1000, 'startPoint', 'mean 50')
%       Same as the first, but we average 1000 fits and start each fit at
%       the mean +- randomly up to 25 % of the range. For example, if the
%       limits were [100 200], 'mean 50' would translate to 150 +- a random
%       number from 0 to 25. 50 indicates the total variation is 50 % of
%       the total range. 
%
% See also: fitoptions, fit, fittype

function result = hyperFit(data, func, fitOpts, varargin)
%% Defaults
defaultNumAvg = 100;
defaultStartPoint = 'rand';

%% Lets parse our inputs
p = inputParser;

% Valid data is a vector or matrix with data sets as column vectors
errMsg = "Valid data is a 2-column matrix. The first column is the x axis. The second is the y axis.";
validData = @(x) assert(isnumeric(x) && ismatrix(x) && (size(x,2) == 2), sprintf(errMsg));
addRequired(p, 'data', validData);

% Valid func is a character vector
errMsg = "Valid func is a chracter vector such as 'a*exp(-x/b) + c'.";
validFunc = @(x) assert(isvector(x) && ischar(x), sprintf(errMsg));
addRequired(p, 'func', validFunc);

% Valid fitOpts is a fitoptions structure with
errMsg = "Valid fitOpts are generated by fitoptions. Its class should start with 'curvefit.'";
validFitOpts = @(x) assert(startsWith(class(x),'curvefit'), sprintf(errMsg));
addRequired(p, 'fitOpts', validFitOpts);

% Valid numAvg input is a single positive integer
errMsg = "A valid input for 'numAvg' should be a single, positive integer.";
validNumAvg = @(x) assert(isreal(x) && isscalar(x) && (sign(x) == 1) && (rem(x,1) == 0), errMsg);
addParameter(p, 'numAvg', defaultNumAvg, validNumAvg);

% Valid startPoint input is a string or character vector
errMsg = "A valid input for startPoint should be a recognized string or character vector such as 'rand' or 'mean'.";
validStartPoint = @(x) assert(isstring(x) || (ischar(x) && isvector(x)), errMsg);
addParameter(p, 'startPoint', defaultStartPoint, validStartPoint);

parse(p, data, func, fitOpts, varargin{:});

%% Create anonymous function based on our select start point algorithm
switch strtok(char(p.Results.startPoint), ' ')
    case 'rand'
        spAlg = @(lo,hi,len) (lo + ((hi - lo) .* rand([1 len])));
    case 'mean'
        if length(strsplit(char(p.Results.startPoint), ' ')) == 1
            spAlg = @(lo,hi,len) mean([lo; hi]);
        elseif length(strsplit(char(p.Results.startPoint), ' ')) == 2
            val = str2double(strsplit(char(p.Results.startPoint), ' '));
            wiggle = val(2) / 50;
            spAlg = @(lo,hi,len) (mean([lo; hi]) + (wiggle .* (rand([1 len]) - 0.5) .* (hi - lo)));
        else
            error(['startPoint argument ''' char(p.Results.startPoint) ''' not recognized.'])
        end
    case 'low'
        spAlg = @(lo,hi,len) lo;
    case 'high'
        spAlg = @(lo,hi,len) hi;
    otherwise
        error(['startPoint argument ''' char(p.Results.startPoint) ''' not recognized.'])
end

%% Assign our data
x = p.Results.data(:,1);
y = p.Results.data(:,2);

curveVars = NaN([p.Results.numAvg length(p.Results.fitOpts.Lower)]);

%% let's fit the curve a bunch of times and get the average fit
for avgIdx = 1:p.Results.numAvg

    % Fetch the given fit parameters.
    s = p.Results.fitOpts;
    % re-randomize our start points to keep fitting honest
    s.Startpoint = spAlg(s.Lower, s.Upper, length(s.Lower));


    % Define our fit (after we make those parameters randomized)
    f = fittype(p.Results.func,'options',s);

    try % if the fit fails, don't give up
        % Fit that guy
        [ourCurve,gof] = fit(x,y,f);
    catch
        gof.adjrsquare = 0; % if it fails to fit, the rsquare is 0
        curveVars(avgIdx, :) = NaN([1 length(s.Lower)]);
    end

    % When the rsquare is too low, try to fit again up to 10 more times
    z=1;
    while (gof.adjrsquare < 0.80) && (z <= 10)
        s.Startpoint = spAlg(s.Lower, s.Upper, length(s.Lower));
        f = fittype(p.Results.func,'options',s);
        
        try % if the fit fails, don't give up
            % Fit that guy
            [ourCurve,gof] = fit(x,y,f);
        catch
            gof.adjrsquare = 0; % if it fails to fit, the rsquare is 0
            curveVars(avgIdx, :) = NaN([1 length(s.Lower)]);
        end
        z = z + 1;
    end

    % If the rsquare is still too low, we can just NaN the data so it
    % doesn't mess up our averages
    if gof.adjrsquare < 0.80
        curveVars(avgIdx, :) = NaN([1 length(s.Lower)]);
    else
        curveVars(avgIdx, :) = coeffvalues(ourCurve);
    end
end

%% Do a final fit based on the average curve
avgCurve = mean(curveVars, 1);

s = p.Results.fitOpts;
s.Lower = avgCurve.*(0.9.^(sign(avgCurve)))-1e-8;
s.Upper = avgCurve.*(1.1.^(sign(avgCurve)))+1e-8;
s.Startpoint = avgCurve;

f = fittype(p.Results.func,'options',s);

[finalCurve,finalGof] = fit(x,y,f);
finalCoeff = coeffvalues(finalCurve);
finalConfi = confint(finalCurve);


%% Handle output
result.curveVars = curveVars;
result.avgCurve = mean(curveVars, 1);
result.finalCurve = finalCurve;
result.finalGof = finalGof;
result.finalCoefficients = finalCoeff;
result.finalConfidence = finalConfi;
result.function = p.Results.func;
result.fitOptions = p.Results.fitOpts;

end









